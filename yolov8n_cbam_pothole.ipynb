{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  YOLOv8n + CBAM for Pothole Detection (Full Notebook)\n",
    "\n",
    "End-to-end pipeline with:\n",
    "- Custom **CBAM** attention integrated into YOLOv8n (C2f + SPPF)\n",
    "- Train/Val on your pothole dataset\n",
    "- Curves, metrics, tâ€‘SNE (optional), sample inference, ONNX/TorchScript export\n",
    "\n",
    "**Paths assume Kaggle dataset layout**:\n",
    "`/kaggle/input/pothole-dataset-6knew/{train,valid,test}/{images,labels}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q ultralytics==8.3.0\n",
    "!pip install -q torch torchvision\n",
    "\n",
    "import os, sys, glob, math, json, random, shutil, time, pathlib\n",
    "from pathlib import Path\n",
    "print('Python:', sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "print('Torch:', torch.__version__)\n",
    "try:\n",
    "    import torchvision\n",
    "    print('TorchVision:', torchvision.__version__)\n",
    "except Exception as e:\n",
    "    print('TorchVision not found:', e)\n",
    "import ultralytics\n",
    "print('Ultralytics:', ultralytics.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Define CBAM + Custom Blocks\n",
    "We build `CBAM`, `C2fCBAM`, and `SPPF_CBAM` as drop-in modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics.nn.modules import Conv, Bottleneck\n",
    "try:\n",
    "    from ultralytics.nn.modules.block import SPPF\n",
    "except Exception:\n",
    "    from ultralytics.nn.modules import SPPF\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super().__init__()\n",
    "        mid = max(1, in_channels // reduction)\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_channels, mid, 1, bias=False)\n",
    "        self.fc2 = nn.Conv2d(mid, in_channels, 1, bias=False)\n",
    "    def forward(self, x):\n",
    "        a = self.fc2(torch.relu(self.fc1(self.avg(x))))\n",
    "        m = self.fc2(torch.relu(self.fc1(self.max(x))))\n",
    "        s = torch.sigmoid(a + m)\n",
    "        return x * s\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, k=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k//2, bias=False)\n",
    "    def forward(self, x):\n",
    "        avg = torch.mean(x, 1, keepdim=True)\n",
    "        mx, _ = torch.max(x, 1, keepdim=True)\n",
    "        s = torch.sigmoid(self.conv(torch.cat([avg, mx], 1)))\n",
    "        return x * s\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(in_channels, reduction)\n",
    "        self.sa = SpatialAttention(7)\n",
    "    def forward(self, x):\n",
    "        return self.sa(self.ca(x))\n",
    "\n",
    "class C2fCBAM(nn.Module):\n",
    "    \"\"\"C2f-like block with CBAM applied to the output.\"\"\"\n",
    "    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5, reduction=16):\n",
    "        super().__init__()\n",
    "        c_ = int(c2 * e)\n",
    "        self.cv1 = Conv(c1, c_, 1, 1)\n",
    "        self.cv2 = Conv(c1, c_, 1, 1)\n",
    "        self.m = nn.ModuleList([Bottleneck(c_, c_, shortcut, g, k=(3, 3)) for _ in range(n)])\n",
    "        self.cv3 = Conv(2 * c_, c2, 1, 1)\n",
    "        self.cbam = CBAM(c2, reduction)\n",
    "    def forward(self, x):\n",
    "        y1 = self.cv1(x)\n",
    "        y2 = self.cv2(x)\n",
    "        for m in self.m:\n",
    "            y2 = m(y2)\n",
    "        y = self.cv3(torch.cat((y1, y2), 1))\n",
    "        return self.cbam(y)\n",
    "\n",
    "class SPPF_CBAM(nn.Module):\n",
    "    def __init__(self, c1, c2, k=5, reduction=16):\n",
    "        super().__init__()\n",
    "        self.sppf = SPPF(c1, c2, k)\n",
    "        self.cbam = CBAM(c2, reduction)\n",
    "    def forward(self, x):\n",
    "        return self.cbam(self.sppf(x))\n",
    "\n",
    "print('CBAM modules declared')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Write Model YAML with CBAM blocks\n",
    "This swaps deeper C2f and SPPF with CBAM variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "yaml_content = '''\n",
    "nc: 1\n",
    "names: ['Pothole']\n",
    "depth_multiple: 0.33\n",
    "width_multiple: 0.25\n",
    "\n",
    "backbone:\n",
    "  - [-1, 1, Conv, [64, 3, 2]]\n",
    "  - [-1, 1, Conv, [128, 3, 2]]\n",
    "  - [-1, 3, C2fCBAM, [128, True]]\n",
    "  - [-1, 1, Conv, [256, 3, 2]]\n",
    "  - [-1, 6, C2fCBAM, [256, True]]\n",
    "  - [-1, 1, Conv, [512, 3, 2]]\n",
    "  - [-1, 6, C2fCBAM, [512, True]]\n",
    "  - [-1, 1, SPPF_CBAM, [512, 5]]\n",
    "\n",
    "neck:\n",
    "  - [-1, 1, Conv, [256, 1, 1]]\n",
    "  - [[-1, 6], 1, nn.Upsample, [None, 2, 'nearest']]\n",
    "  - [[-1, 4], 1, Concat, [1]]\n",
    "  - [-1, 3, C2fCBAM, [256]]\n",
    "\n",
    "  - [-1, 1, Conv, [128, 1, 1]]\n",
    "  - [[-1, 2], 1, nn.Upsample, [None, 2, 'nearest']]\n",
    "  - [[-1, 2], 1, Concat, [1]]\n",
    "  - [-1, 3, C2fCBAM, [128]]\n",
    "\n",
    "  - [-1, 1, Conv, [128, 3, 2]]\n",
    "  - [[-1, 11], 1, Concat, [1]]\n",
    "  - [-1, 3, C2fCBAM, [256]]\n",
    "\n",
    "  - [-1, 1, Conv, [256, 3, 2]]\n",
    "  - [[-1, 7], 1, Concat, [1]]\n",
    "  - [-1, 3, C2fCBAM, [512]]\n",
    "\n",
    "head:\n",
    "  - [[15, 18, 21], 1, Detect, [nc]]\n",
    "'''\n",
    "with open('models/yolov8n_cbam.yaml', 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "print('Wrote models/yolov8n_cbam.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Dataset YAML & quick checks\n",
    "Confirm dataset folders exist and show a small summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_YAML = 'pothole_dataset.yaml'\n",
    "dataset_yaml = '''# auto-generated\n",
    "train: /kaggle/input/pothole-dataset-6knew/train\n",
    "val:   /kaggle/input/pothole-dataset-6knew/valid\n",
    "test:  /kaggle/input/pothole-dataset-6knew/test\n",
    "nc: 1\n",
    "names: ['Pothole']\n",
    "'''\n",
    "open(DATA_YAML, 'w').write(dataset_yaml)\n",
    "print('Wrote', DATA_YAML)\n",
    "\n",
    "for split in ['train','valid','test']:\n",
    "    img_dir = f'/kaggle/input/pothole-dataset-6knew/{split}/images'\n",
    "    lbl_dir = f'/kaggle/input/pothole-dataset-6knew/{split}/labels'\n",
    "    exists = os.path.isdir(img_dir)\n",
    "    cnt = len(glob.glob(os.path.join(img_dir, '*.jpg'))) + len(glob.glob(os.path.join(img_dir, '*.png')))\n",
    "    print(f'{split}: images={cnt} dir_exists={exists}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Build model & warm-start from `yolov8n.pt`\n",
    "We load our YAML model and then partially load official YOLOv8n weights for faster convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbam_modules \n",
    "model = YOLO('models/yolov8n_cbam.yaml')\n",
    "try:\n",
    "    model.load('yolov8n.pt')\n",
    "    print('Base weights loaded')\n",
    "except Exception as e:\n",
    "    print('Could not load base weights:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Train\n",
    "Training knobs are tuned for small single-class datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = dict(\n",
    "    data=DATA_YAML,\n",
    "    epochs=350,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=0,\n",
    "    lr0=0.005,\n",
    "    lrf=0.1,\n",
    "    momentum=0.937,\n",
    "    weight_decay=5e-4,\n",
    "    warmup_epochs=3.0,\n",
    "    cos_lr=True,\n",
    "    patience=80,\n",
    "    optimizer='SGD',\n",
    "    amp=True,\n",
    "    ema=True,\n",
    "    augment=True,\n",
    ")\n",
    "print('Training args:', train_args)\n",
    "results = model.train(**train_args)\n",
    "print('training done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Validate & Plot Curves\n",
    "Generate metrics plots from `results.csv` in the latest run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = model.val(split='val', plots=True, save_json=True)\n",
    "print('val:', val)\n",
    "\n",
    "runs_root = 'runs/detect'\n",
    "latest = None\n",
    "if os.path.isdir(runs_root):\n",
    "    subdirs = [os.path.join(runs_root, d) for d in os.listdir(runs_root) if d.startswith('train')]\n",
    "    if subdirs:\n",
    "        latest = max(subdirs, key=os.path.getmtime)\n",
    "print('latest run:', latest)\n",
    "\n",
    "if latest:\n",
    "    csv_path = os.path.join(latest, 'results.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        epochs = np.arange(len(df))\n",
    "\n",
    "        plt.figure(figsize=(9,5))\n",
    "        for k in ['train/box_loss','val/box_loss','train/cls_loss','val/cls_loss','val/dfl_loss']:\n",
    "            if k in df.columns:\n",
    "                plt.plot(epochs, df[k], label=k)\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss curves'); plt.legend(); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(latest, 'loss_curves_cbam.png'))\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(9,5))\n",
    "        metric_cols = [\n",
    "            'metrics/precision(B)', 'metrics/recall(B)',\n",
    "            'metrics/mAP50(B)', 'metrics/mAP50-95(B)',\n",
    "            'metrics/mAP_0.5(B)', 'metrics/mAP_0.5:0.95(B)'\n",
    "        ]\n",
    "        plotted = False\n",
    "        for col in metric_cols:\n",
    "            if col in df.columns:\n",
    "                plt.plot(epochs, df[col], label=col); plotted=True\n",
    "        if plotted:\n",
    "            plt.xlabel('Epoch'); plt.ylabel('Metric'); plt.title('Validation metrics over epochs'); plt.legend(); plt.tight_layout()\n",
    "            plt.savefig(os.path.join(latest, 'val_metrics_cbam.png'))\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('Metric columns not found in results.csv; skipping metric plot')\n",
    "\n",
    "        df.iloc[-1].to_csv(os.path.join(latest, 'final_metrics_cbam.csv'))\n",
    "        print('Saved final metrics to final_metrics_cbam.csv')\n",
    "    else:\n",
    "        print('results.csv not found in run dir')\n",
    "else:\n",
    "    print('No train run dir found; skip plotting')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Sample Inference & Visualization\n",
    "Run inference on a few validation images and render predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs = sorted(glob.glob('/kaggle/input/pothole-dataset-6knew/valid/images/*.jpg'))[:8]\n",
    "if not sample_imgs:\n",
    "    sample_imgs = sorted(glob.glob('/kaggle/input/pothole-dataset-6knew/valid/images/*.png'))[:8]\n",
    "print('sample count:', len(sample_imgs))\n",
    "\n",
    "if len(sample_imgs):\n",
    "    preds = model.predict(sample_imgs, save=True, imgsz=640, conf=0.25)\n",
    "    print('Saved predicted images under the latest runs folder.')\n",
    "else:\n",
    "    print('No sample images found to run inference.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Export Models (ONNX / TorchScript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.export(format='onnx', opset=12, simplify=True)\n",
    "    print('âœ… Exported ONNX')\n",
    "except Exception as e:\n",
    "    print('ONNX export issue:', e)\n",
    "try:\n",
    "    model.export(format='torchscript')\n",
    "    print('âœ… Exported TorchScript')\n",
    "except Exception as e:\n",
    "    print('TorchScript export issue:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) (Optional) tâ€‘SNE of SPPF features\n",
    "Useful for sanityâ€‘checking clustering of features; may be slow. You can skip if not needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "    from torchvision import transforms\n",
    "    from ultralytics.nn.modules.block import SPPF\n",
    "    feats = []\n",
    "    sppf_layer = None\n",
    "    for m in model.model.modules():\n",
    "        if isinstance(m, SPPF):\n",
    "            sppf_layer = m\n",
    "            break\n",
    "    if sppf_layer is None:\n",
    "        raise RuntimeError('SPPF not found')\n",
    "    def hook_fn(_, __, out):\n",
    "        feats.append(out.detach().flatten(1).cpu())\n",
    "    h = sppf_layer.register_forward_hook(hook_fn)\n",
    "    tfm = transforms.Compose([transforms.Resize((640,640)), transforms.ToTensor()])\n",
    "    paths = sorted(glob.glob('/kaggle/input/pothole-dataset-6knew/valid/images/*.jpg'))[:150]\n",
    "    if not paths:\n",
    "        paths = sorted(glob.glob('/kaggle/input/pothole-dataset-6knew/valid/images/*.png'))[:150]\n",
    "    for p in paths:\n",
    "        img = Image.open(p).convert('RGB')\n",
    "        t = tfm(img).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            _ = model(t)\n",
    "    h.remove()\n",
    "    if len(feats) > 1:\n",
    "        X = torch.cat(feats, 0).numpy()\n",
    "        tsne = TSNE(n_components=2, random_state=0, perplexity=30)\n",
    "        X2 = tsne.fit_transform(X)\n",
    "        plt.figure(figsize=(7,6))\n",
    "        plt.scatter(X2[:,0], X2[:,1], s=10, alpha=0.6)\n",
    "        plt.title('t-SNE of SPPF features (val subset)')\n",
    "        plt.tight_layout()\n",
    "        out_path = os.path.join(latest if latest else '.', 'tsne_sppf.png')\n",
    "        plt.savefig(out_path)\n",
    "        plt.show()\n",
    "        print('Saved t-SNE image at', out_path)\n",
    "    else:\n",
    "        print('Not enough features for t-SNE')\n",
    "except Exception as e:\n",
    "    print('t-SNE skipped:', e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
